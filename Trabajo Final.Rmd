---
title: "R Notebook"
output: html_notebook
--- 

PROPUESTA:
DESAGREGAR LA VARIACIÓN DE PRECIOS DE LAS PROPIEDADES INMOBILIARIAS DURANTE LA PANDEMIA EN UNA UNIDAD DE ANÁLISIS VIRTUAL (MALLA HEXAGONAL)

Construir una malla hexagonal que refleje: 
    1- promedio m2 en venta 01/03/2020 - 31/03/2020
    2- promedio m2 en venta 01/03/2021 - 31/03/2021
  
  Analizar la variación de precios.
  ¿Existe algún patrón espacial claro? 


Incorporar alguna otra variable que pueda llegar a explicarlo, como: 
    - distancia al centro
    - espacios verdes
    - densidad poblacional
    
¿Hay algún tipo de correlación? Estimar 



LIBRERIAS
vroom (cargar datos rapidos)
annotator (te da que hacer cada library)
skimr (analisis estadistico rapido) ---> skimr::skim(df)



Pasos principales para esta parte:

A) CREACIÓN DE HEXÁGONOS
  - explicación creación hexágonos (Unidad de análisis virtual)
  - Creación de la malla


B) DENSIDAD: 
  - Importar radios censales 
  - Graficar por barrios
  - Disolver por hexágonos


C) USOS (SI ALCANZA EL TIEMPO): 
  - Importar RUS (releva. usos del suelo)
  - Agrupar por 5/6 categorías
  - calcular centroides de las parcelas 
  - join espacial del centroide a la malla hexagonal
  - cual es el uso predominante del hexágono?
  
  
D) DATOS TERRENOS EN VENTA (BUENOS AIRES DATA)

  DATASET TERRENOS EN VENTA 2020 (TODO EL AÑO)
  DATASET TERRENOS EN VENTA (POSPANDEMIA: 2°, 3° Y 4° TRIMESTRE 2021)
  
  - exploración de datos (skim) + grafiquitos que pinten
  - limpieza de datos. Eliminar outliers (CREAR FUNCION PARA FILTRAR OUTLIERS?)
  
  Q1-1.5*IQR
  Q3+1.5*IQR
  
Q1=quantile(df$PRECIO, c(.25))
Q3=quantile(df$PRECIO, c(.75))
IQR= Q3-Q1

lim_inf=Q1-1.5*IQR
lim_sup=Q3+1.5*IQR
  
df_filter <- filter(df, PRECIO?? >lim_inf & precio_m2 < lim_sup)

Join espacial con HEXAGONOS 


crear objeto umbral:

umbral <- 4     
OJO: DETERMINAR UMBRAL. HEXÁGONOS CON MENOS INSTANCIAS QUE EL UMBRAL SE ELIMINAN/NO SE TIENEN EN CUENTA POR SESGO

Una vez que tenemos los hexágonos con 2 columnas: promedio Marzo 2020 y promedio Marzo 2021. 

mutate (VARIACION=marzo2021/marzo2020*100) 

GRAFICAR HEXÁGONOS CON PRECIOS 2020 Y 2021
GRAFICAR HEXÁGONOS CON VARIACIÓN 

INTERPRETAR


E) SI SOBRA TIEMPO, VER CORRELACIÓN. .corr (?)

 
  
  
```{r message=FALSE, warning=FALSE}
library(sf)
library(tidyverse)
library(ggplot2)
library(skimr)
library(sp) #??
library(rgeos) #??
library(osmdata) 
```

## Desarrollo

### Creación de hexágonos

En primer lugar vamos a descargar los barrios de CABA

```{r}
barrios_CABA <- st_read("https://cdn.buenosaires.gob.ar/datosabiertos/datasets/barrios/barrios.geojson") %>% 
  select() %>% 
  st_transform(crs = 4326)
```

Creamos la grilla hexagonal

```{r}
grid <- st_make_grid(barrios_CABA, cellsize = .01, what = "polygons", square = FALSE)

grid <- st_sf(index = 1:length(lengths(grid)), grid) %>%  #le agregamos un índice
  st_transform(crs = 4326) #mismo crs
```

Descargaremos el límite de CABA para hacer la intersercción con la grilla

```{r}
bbox_CABA_limite <- getbb("Ciudad Autónoma de Buenos Aires, Argentina", format_out = "sf_polygon")
bbox_CABA_limite <- bbox_CABA_limite$multipolygon
```

```{r}
hex <- st_intersection(grid, bbox_CABA_limite)
```
Veamos cómo se ve: 

```{r}
ggplot()+
  geom_sf(data = barrios_CABA, fill="grey85", size=.8) + 
  geom_sf(data=hex, fill=NA, color="grey45")+
  theme_void()
```

Muy bien, esta será nuestra Unidad de Análisis a partide ahora. 


### Densidad poblacional

Vamos a cargar la info de radios censales de GCABA

```{r}
radios <- st_read("https://cdn.buenosaires.gob.ar/datosabiertos/datasets/informacion-censal-por-radio/caba_radios_censales.geojson") %>% 
  select(-WKT) %>% 
  st_transform(crs = 4326) %>% 
  mutate(AREA=(as.integer(st_area(.)))*0.0001) %>% #calculamos el área y la convertimos en Ha
  mutate(DENSIDAD=(as.integer(TOTAL_POB))/AREA) #calculamos la densidad poblacional de cada radio censal (hab/Ha)
```
Veamos cómo queda sobre la grilla... en primer lugar, sólo superponiendo: 

```{r}
ggplot()+
  geom_sf(data=radios, aes(fill=DENSIDAD), color=NA)+
  geom_sf(data = barrios_CABA, fill=NA, size=.8) + 
  geom_sf(data=hex, fill=NA, color="white")+
  scale_fill_viridis_c()+
  theme_void()
```

Ahora sí, sin sobreescribir la grilla haremos el join espacial de los centroides de los radios a la grilla (UA). 
Es decir, todos los centroides de los radios censales que caigan dentro del mismo hexágono, formarán parte del mismo.

```{r}
hex2 <- st_centroid(radios) %>% st_join(hex)
```
Hasta acá tenemos la info asociada en forma de puntos. 
Veámosla:

```{r}
ggplot()+
  geom_sf(data=hex, fill="grey85") +
  geom_sf(data=hex2, aes(color=DENSIDAD))+
  scale_color_viridis_c()+
  theme_void()
```

Vamos a hacer que el hexágono tome como valor el promedio de todos los valores incolucrados.

```{r}
hex3 <- hex2 %>% 
  group_by(index) %>% #agrupamos por ID de hexágono
  summarise(PROM_DENS=mean(DENSIDAD), INSTANCIAS=n()) %>% 
  #resumimos por densidad pero también por cantidad de radios que caen dentro del hexágonos
  as.data.frame() %>% 
  select(-geometry)
```

```{r}
hex_densidad <- left_join(hex3, hex, by="index") #union espacial con la grilla original
```


Entendiendo que un hexágonos con muy pocos valores puede estar sesgados por valores poco representativos, vamos a determinar un umbral. En el caso de que el hexágono no registra menos valores que dicho límite inferior, no lo tenderemos en cuenta para nuestra correlación.

```{r}
umbral <- 4
```

```{r}
ggplot()+
  geom_sf(data=barrios_CABA, fill="grey85") +
  geom_sf(data=hex_densidad, aes(fill=PROM_DENS, geometry = grid))+
  geom_sf(data=hex_densidad %>% filter(INSTANCIAS<umbral), aes(geometry = grid), fill="red")+
  scale_fill_viridis_c() +
  theme_void()
```
 
 
 
### RUS 

Para facilitar el trabajo en equipo, este set de datos fue procesado en RUS.Rmd, dentro del mismo repositorio. 
Resume la cantidad de usos que regista cada parcela. 
 
```{r}
RUS <- st_read("data/rus-procesado/RUS-grupo-geo.csv")
```
```{r}
#RUS_grupo <- RUS %>% 
 # group_by(SMP) %>% 
 # summarise(CANTIDAD=n())
```

Convertimos el set de datos de usos en datos geográfico

```{r}
RUS_geo <- RUS %>% 
  st_as_sf(coords = c("X", "Y"), crs = 4326)
```

```{r}
hex2 <- RUS_geo %>% st_join(hex)
```

```{r}
hex3 <- hex2 %>% 
  as.data.frame() %>% 
  select(-geometry) %>% 
  group_by(index, CANTIDAD) %>% #agrupamos por ID de hexágono
  summarise(CANTIDAD_USOS=sum(as.numeric(CANTIDAD)), INSTANCIAS=n()) %>% 
  mutate(DIVERSIDAD_USOS=CANTIDAD_USOS/INSTANCIAS) %>% 
  select(-CANTIDAD, -INSTANCIAS)

  #resumimos por cantidad de usos por hexágono
```

```{r}
hex_densidad_usos <- left_join(hex3, hex_densidad, by="index") #union espacial con la grilla que ya tiene la densidad
```

```{r}
quiebres <- c(0,0.2,0.4,0.6,0.8,1)


ggplot()+
  geom_sf(data=barrios_CABA, fill="grey85") +
  geom_sf(data=hex_densidad_usos, aes(fill=(cut(DIVERSIDAD_USOS, breaks = seq(0, 400, 50))), geometry = grid))+
  scale_fill_viridis_d() +
  theme_void()+
  labs(title = "Diversidad de usos",
       subtitle = "Ciudad Autónoma de Buenos Aires",
       fill = " Diversidad de usos/\n\ cantidad de parcelas",
       caption = "Fuente: GCBA data")
```


### TERRENOS 2019

Para facilitar el trabajo en equipo, este set de datos fue procesado en TERRENOS 2019.Rmd, dentro del mismo repositorio. Resume la venta de terrenos en CABA en el año 2019



```{r}
Terrenos_2019 <- read_sf("data/terrenos-2019/Terrenos_venta_2019.shp") 

Terrenos_2019 <- st_transform(Terrenos_2019, crs=4326) 
```

```{r}
summary(Terrenos_2019)
```

```{r}
dim(Terrenos_2019)
```
```{r}
head(Terrenos_2019)
```



